$ terraform --version
Terraform v1.10.5
on windows_386
+ provider registry.terraform.io/hashicorp/aws v5.84.0

Your version of Terraform is out of date! The latest version
is v1.11.0. You can update by downloading from https://www.terraform.io/downloads.html


https://www.terraform-best-practices.com/naming
https://developer.hashicorp.com/terraform/tutorials/aws-get-started/aws-change
https://developer.hashicorp.com/terraform/language/style
https://github.com/terraform-aws-modules/terraform-aws-alb  -- open source modules
https://aws.amazon.com/marketplace/pp/prodview-y3m73u6jd5srk?applicationId=AWS-EC2-Console&ref_=beagle&sr=0-1
https://openvpn.net/as-docs/aws-ec2.html#connect-to-your-new-ami-76631

https://developer.hashicorp.com/terraform/tutorials/aws/aws-rds  --- conatains steps to create resources
https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/db_instance  -- syntax for the resources
https://github.com/terraform-aws-modules/terraform-aws-rds -- open source module for resources

cd D:/GitHub/DAWS-2025-82S/repos/14-expense-infra-dev
 
for i in $(ls -d *);do cd $i;terraform apply -auto-approve;cd ..;done
 
Destroy all resources(Expense Infra)
----------------------
rajas@ManDev MINGW64 /d/GitHub/DAWS-2025-82S/repos/14-expense-infra-dev (main)
$  ls -dr *
50-app-alb/  40-rds/  30-vpn/  20-bastion/  10-sg/  00-vpc/

for i in $(ls -dr *);do cd $i;terraform destroy -auto-approve;cd ..;done

required_providers
provider
cidr_blocks
output
locals
count based loop -- to loop list
for_each loop -- to loop map
backend block -- for s3 bucket and DynamoDB configuration to store and secure state file
create DynamoDB table with Partition Key as "LockID" other it will fail for other partition key
dynamic blocks
provisioners
connection block -- to connect to the server created using connection details
multiple env using
1. tfvars
2. workspaces
3. maintain different repos for diff environment
lookup() -- function to lookup(get) a value in map
terraform modules
validation block to validate variables
slice function -- to get values from list
VPC
referring  git terraform module
join function -- convert list to string
split function --- convert to list
load balancer
target group
AutoScaling
Launch template
app load balancer
terrafrom-aws-alb  --- opensource module
Listener and Rules
create listener with fixed response(Without target group)
create alias of route 53 record for load balancer since LB will not have IP
VPN
file function -- to read file
user_data
ansible pull
null_resource
file provisioner -- to copy the file to the resource
ssl certificate creation and validation using ACM

nslookup.io
nslookup mysql-dev.raj82s.online


Terraform resources
--------------------
aws_instance
aws_security_group
ingress
egress
aws_route53_record
aws_vpc
aws_internet_gateway
aws_subnet
aws_eip
aws_nat_gateway
aws_route_table
aws_route
aws_route_table_association
aws_vpc_peering_connection
aws_ssm_parameter  -- to upload terrafrom output to centralised location
aws_security_group_rule
terrafrom-aws-alb("terraform-aws-modules/alb/aws") -- open source modules
aws_lb_listener
aws_key_pair --- to upload public key while creating new instance
aws_db_subnet_group -- subnet group for RDS(MYSQL) DB creation
terraform-aws-rds("terraform-aws-modules/rds/aws")  -- opensource module to create rds(MYSQL) DB
null_resource
aws_ec2_instance_state -- to stop(control) ec2 instance
aws_ami_from_instance -- to create AMI from ec2 instance
aws_lb_target_group -- to create target group and health check block 
aws_launch_template -- to create template with the image
aws_autoscaling_group -- to create autoscaling group with launch template and target group
aws_lb_listener_rule --- add listener rule to load balancer listener
aws_acm_certificate  -- create ssl certificate
aws_route53_record -- to confirm the owner of the domain
aws_acm_certificate_validation -- validate certificate

data sources
--------------
aws_ami
aws_vpc
aws_instance
aws_availability_zones
aws_route_table


-------------------------------------------------------------------------------------------------------------
terraform commands
-------------------------------------------------------------------------------------------------------------
terraform init   --- Downloads and install provider
terraform fmt    --- format the files properly
terraform validate --- validate the configuration
terraform plan
terraform apply  --- to create resources
terraform apply -auto-approve --- to create resources without confirmation
terraform destroy  --- to destroy resources
terraform destroy -auto-approve  --- to destroy resources without confirmation 

terraform show  --- Inspect the current state
terraform state list ---  to list the resources in your project's state

// By default terraform will load vars from *.auto.tfvars and terraform.tfvars files
// If the file name  is different to load vars from different file name use -var-file=<filename> option
// terraform plan -var-file=test.tfvars
// terraform apply -var-file=test.tfvars

command line var:
-----------------
terraform plan -var "instance_type=t3.large"
terraform plan -var "instance_type=t3.large" -var "from_port=99"

env var:
--------
export TF_VAR_instance_type="t3.xlarge"
unset TF_VAR_instance_type

If you wish to attempt automatic migration of the state, use
		terraform init -migrate-state
If you wish to store the current configuration with no changes to the state, use 
		terraform init -reconfigure
		
For dev:

terraform init -backend-config=dev/backend.tf -reconfigure
terraform plan -var-file=dev/dev.tfvars
terraform apply -auto-approve -var-file=dev/dev.tfvars
terraform destroy -auto-approve -var-file=dev/dev.tfvars

For Prod:
terraform init -backend-config=prod/backend.tf -reconfigure
terraform plan -var-file=prod/prod.tfvars
terraform apply -auto-approve -var-file=prod/prod.tfvars
terraform destroy -auto-approve -var-file=prod/prod.tfvars		

-------------------------------------------------------------------------------------------------------------
variables
-------------------------------------------------------------------------------------------------------------
varaibles can be accessed by using
var.<VariableName>

Resources can be accessed by using
<ResourceType>.<ResourceName>.<Attributes>

Data sources can be accessedd by using
data.<DataSourceType>.<DataSourceName>.<Attributes>

locals can be accessedd by using
local.<VariableName>


Output will be print by using output block

// print var value
output  "variable_output" {
  value       = var.<VariableName>
}
// print resource output
output  "resource_output" {
  value       = <ResourceType>.<ResourceName>.<Attributes>
}
// print DataSource output
output  "datasource_output" {
  value       = data.<DataSourceType>.<DataSourceName>.<Attributes>
}
// print locals variable output
output  "output_local_variable" {
  value  = local.<VariableName>
}
// output multiple variables
output "instance_info" {
  value = {
    instance_id      = data.aws_instance.example.id
    private_ip       = data.aws_instance.example.private_ip
    public_ip        = data.aws_instance.example.public_ip
  }
}


sudo tail -f /var/log/cloud-init-output.log -- to check user data output


when changed backend configuration
rajas@ManDev MINGW64 /d/GitHub/DAWS-2025-82S/repos/06-terraform/07-remote-state (main)
$   terraform init
Initializing the backend...
╷
│ Error: Backend configuration changed
│
│ A change in the backend configuration has been detected, which may require
│ migrating existing state.
│
│ If you wish to attempt automatic migration of the state, use "terraform
│ init -migrate-state".
│ If you wish to store the current configuration with no changes to the
│ state, use "terraform init -reconfigure".


│ If you wish to attempt automatic migration of the state, use "terraform
│ init -migrate-state".
│ If you wish to store the current configuration with no changes to the
│ state, use "terraform init -reconfigure".

----------------------------------------------------------------------------------------------------------
create DynamoDB table with Partition Key as "LockID" otherwise it will fail for other partition key
-------------------------------------------------------------------------------------------------
$ terraform apply -auto-approve
Acquiring state lock. This may take a few moments...
╷
│ Error: Error acquiring the state lock
│
│ Error message: operation error DynamoDB: PutItem, https response error
│ StatusCode: 400, RequestID:
│ NDIJ4BSVSFP7E0AHFQS7OFKJFBVV4KQNSO5AEMVJF66Q9ASUAAJG, api error
│ ValidationException: One or more parameter values were invalid: Missing the
│ key testpartitionkey in the item
│ Unable to retrieve item from DynamoDB table "82s-state-locking": operation
│ error DynamoDB: GetItem, https response error StatusCode: 400, RequestID:
│ KMBISS2HOHU93J4UDHFOL9ODENVV4KQNSO5AEMVJF66Q9ASUAAJG, api error
│ ValidationException: The provided key element does not match the schema
│
│ Terraform acquires a state lock to protect the state from being written
│ by multiple users at the same time. Please resolve the issue above and try
│ again. For most commands, you can disable locking with the "-lock=false"
│ flag, but this is not recommended.

---------------------------------------------------------
terraform workspaces commands
==============================
terraform.workspace --variable--> prod

terraform workspace new  <workspacename>--- to create new work space
terraform workspace list -- to list workspaces

terraform workspace select <workspacename>  --  to switch workspace
terraform plan
terraform apply -auto-approve

referring  git terraform module instead of local
-------------------------------
    #source = "github.com/DAWS-2025-82S/10-terraform-aws-vpc"
    source = "git::https://github.com/DAWS-2025-82S/10-terraform-aws-vpc.git?ref=main"

to get module updates
terraform get -update

check ec2 creation without security group
check variables -var "varname1=value" 
check renaming terraform.tfvars with different name

check null resource provisioner



-------------------------------------------------------------------------------------------------------------------------------------------------------------------
EC2 Autoscaling steps:

1. instance creation
2. connect to server using connection block
3. copy the shell script into server using file provisioner block
	install ansible
	ansible-pull -i localhost, -U URL main.yaml -e COMPONENT=backend -e ENVIRONMENT=dev
4. remote-exec
	chmod +x backend.sh
	sudo sh backend.sh
5. ansible configures backend
6. stop instance
7. take the AMI
8. create target group
9. launch template --> AMI
10. ASG -->> launch template


__________________________________________________________________________________________________________________________________________________________________

Getting error below while provisioning backend using terraform since VPN is required to connect 
Sol: connect to VPN and run 60-backend again

Plan: 2 to add, 0 to change, 0 to destroy.
aws_instance.backend: Creating...
aws_instance.backend: Still creating... [10s elapsed]
aws_instance.backend: Creation complete after 16s [id=i-0f6a0e2a08295004b]
null_resource.backend: Creating...
null_resource.backend: Provisioning with 'file'...
null_resource.backend: Still creating... [10s elapsed]
null_resource.backend: Still creating... [20s elapsed]
null_resource.backend: Still creating... [30s elapsed]
null_resource.backend: Still creating... [40s elapsed]
null_resource.backend: Still creating... [50s elapsed]
null_resource.backend: Still creating... [1m0s elapsed]
null_resource.backend: Still creating... [1m10s elapsed]
null_resource.backend: Still creating... [1m20s elapsed]
null_resource.backend: Still creating... [1m30s elapsed]
null_resource.backend: Still creating... [1m40s elapsed]
null_resource.backend: Still creating... [1m50s elapsed]
null_resource.backend: Still creating... [2m0s elapsed]
null_resource.backend: Still creating... [2m10s elapsed]
null_resource.backend: Still creating... [2m20s elapsed]
null_resource.backend: Still creating... [2m30s elapsed]
null_resource.backend: Still creating... [2m40s elapsed]
null_resource.backend: Still creating... [2m50s elapsed]
null_resource.backend: Still creating... [3m0s elapsed]
null_resource.backend: Still creating... [3m10s elapsed]
null_resource.backend: Still creating... [3m20s elapsed]
null_resource.backend: Still creating... [3m30s elapsed]
null_resource.backend: Still creating... [3m40s elapsed]
null_resource.backend: Still creating... [3m50s elapsed]
null_resource.backend: Still creating... [4m0s elapsed]
null_resource.backend: Still creating... [4m10s elapsed]
null_resource.backend: Still creating... [4m20s elapsed]
null_resource.backend: Still creating... [4m30s elapsed]
null_resource.backend: Still creating... [4m40s elapsed]
null_resource.backend: Still creating... [4m50s elapsed]
╷
│ Error: file provisioner error
│
│   with null_resource.backend,
│   on main.tf line 30, in resource "null_resource" "backend":
│   30:   provisioner "file" {
│
│ timeout - last error: dial tcp 10.0.11.164:22: i/o timeout
╵
Releasing state lock. This may take a few moments...

-----------------------------------------------------------------------------------------------------------------------------------
After connecting to VPN failed with error
sol:
1)If running a script, check for hidden characters:

	cat -A backend.sh
2)If you see \r, remove them using:
 sed -i 's/\r//g' backend.sh

Windows-style line endings (\r\n) in scripts

If you're running a script on a Linux system that was created on Windows, it may have \r characters at the end of lines.
Solution: Convert the script using dos2unix

	dos2unix script.sh
	
other sol: In Visual Studio select LF at the bottom of the visual studio	
---------------------------------------------

$ cat -A backend.sh
#!/bin/bash^M$
^M$
dnf install ansible -y^M$
# push^M$
# ansible-playbook -i inventory mysql.yaml^M$
^M$
#pull^M$
ansible-pull  -i localhost, -U https://github.com/joindevops-1/expense-ansible-roles-tf1.git main.yaml -e COMPONENT=backend -e ENVIRONMENT=$1



----------------------------------------------

null_resource.backend: Still creating... [10s elapsed]
null_resource.backend (remote-exec): /tmp/backend.sh: line 2: $'\r': command not found
null_resource.backend (remote-exec): usage: dnf [-c [config file]] [-q]
null_resource.backend (remote-exec):            [-v] [--version]
null_resource.backend (remote-exec):            [--installroot [path]]
null_resource.backend (remote-exec):            [--nodocs] [--noplugins]
null_resource.backend (remote-exec):            [--enableplugin [plugin]]
null_resource.backend (remote-exec):            [--disableplugin [plugin]]
null_resource.backend (remote-exec):            [--releasever RELEASEVER]
null_resource.backend (remote-exec):            [--setopt SETOPTS]
null_resource.backend (remote-exec):            [--skip-broken] [-h]
null_resource.backend (remote-exec):            [--allowerasing]
null_resource.backend (remote-exec):            [-b | --nobest] [-C]
null_resource.backend (remote-exec):            [-R [minutes]]
null_resource.backend (remote-exec):            [-d [debug level]]
null_resource.backend (remote-exec):            [--debugsolver]
null_resource.backend (remote-exec):            [--showduplicates]
null_resource.backend (remote-exec):            [-e ERRORLEVEL]
null_resource.backend (remote-exec):            [--obsoletes]
null_resource.backend (remote-exec):            [--rpmverbosity [debug level name]]
null_resource.backend (remote-exec):            [-y] [--assumeno]
null_resource.backend (remote-exec):            [--enablerepo [repo]]
null_resource.backend (remote-exec):            [--disablerepo [repo] |
null_resource.backend (remote-exec):            --repo [repo]]
null_resource.backend (remote-exec):            [--enable | --disable]
null_resource.backend (remote-exec):            [-x [package]]
null_resource.backend (remote-exec):            [--disableexcludes [repo]]
null_resource.backend (remote-exec):            [--repofrompath [repo,path]]
null_resource.backend (remote-exec):            [--noautoremove]
null_resource.backend (remote-exec):            [--nogpgcheck]
null_resource.backend (remote-exec):            [--color COLOR] [--refresh]
null_resource.backend (remote-exec):            [-4] [-6]
null_resource.backend (remote-exec):            [--destdir DESTDIR]
null_resource.backend (remote-exec):            [--downloadonly]
null_resource.backend (remote-exec):            [--comment COMMENT]
null_resource.backend (remote-exec):            [--bugfix] [--enhancement]
null_resource.backend (remote-exec):            [--newpackage] [--security]
null_resource.backend (remote-exec):            [--advisory ADVISORY]
null_resource.backend (remote-exec):            [--bz BUGZILLA]
null_resource.backend (remote-exec):            [--cve CVES]
null_resource.backend (remote-exec):            [--sec-severity {Critical,Important,Moderate,Low}]
null_resource.backend (remote-exec):            [--forcearch ARCH]
null_resource.backend (remote-exec): Command line error: argument -y/--assumeyes: ignored explicit argument '\r'
null_resource.backend (remote-exec): /tmp/backend.sh: line 6: $'\r': command not found
null_resource.backend (remote-exec): /tmp/backend.sh: line 8: ansible-pull: command not found
╷
│ Error: remote-exec provisioner error
│
│   with null_resource.backend,
│   on main.tf line 35, in resource "null_resource" "backend":
│   35:   provisioner "remote-exec" {
│
│ error executing "/tmp/terraform_589911068.sh": Process exited with status
│ 127
╵
Releasing state lock. This may take a few moments...

-----------------------------------------------------------------------------------------------------------------------------

aws_autoscaling_group.backend: Still creating... [30s elapsed]
aws_autoscaling_group.backend: Creation complete after 36s [id=expense-dev-backend]
╷
│ Warning: 'launch_template' always triggers an instance refresh and can be removed
│
│   with aws_autoscaling_group.backend,
│   on main.tf line 126, in resource "aws_autoscaling_group" "backend":
│  126:     triggers = ["launch_template"]
│
│ (and 2 more similar warnings elsewhere)
╵
Releasing state lock. This may take a few moments...
----------------------------------------------------------------------------------------------
Deletion of AMI,target group and autoscaling failed when
deregistration delay default value is 5 minutes
and aws_autoscaling_group(auto scaling) timeout value is also 5 minutes

to fix this change the deregistration delay of target group less than timeout value
change deregistration delay value to 60 seconds
and auto scaling timeout value to 10 minutes
----------------------------------------------------------------------------------------------
null_resource won't trigger and instance won't delete if there is no triggers configuration
for autoscaling concept

resource "null_resource" "backend_delete" {

  triggers = {
    instance_id = aws_instance.backend.id
  }
  
----------------------------------------------------------------------------------------------
  
  