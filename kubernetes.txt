eksctl
kubectl
namespace
pod
labels
annotations
env
resources
configMapRef
secrets
services
3 types of services
	1. cluster IP --> default, only works internally i.e., pod to pod
	2. NodePort --> external requests
	3. LoadBalancer --> only works with cloud providers. here service open classic LB. 


eksctl -- AWS command line tool to create and manage EKS cluster 
For real projects terraform is used to create EKS cluster
eksctl installation -- For cluster creation
kubectl installation  -- For cluster  interaction
We wiil use same EC2 instance used for docker to setup eksctl,kubectl

https://docs.aws.amazon.com/eks/latest/userguide/install-kubectl.html
https://eksctl.io/installation/

https://github.com/eksctl-io/eksctl/blob/main/examples/01-simple-cluster.yaml

sudo tail -f /var/log/cloud-init-output.log -- to check user data output

https://kubernetes.io/  -- official doc and can be used for CKA exam

1. create one linux server as workstation
2. install docker to build images
3. run aws configure to provide authentication
4. install eksctl to create and manage EKS cluster
5. install kubectl to work with eks cluster

eksctl installation
-------------------
curl -O https://s3.us-west-2.amazonaws.com/amazon-eks/1.32.0/2024-12-20/bin/linux/amd64/kubectl.sha256
chmod +x ./kubectl
sudo mv kubectl /usr/local/bin/kubectl

# for ARM systems, set ARCH to: `arm64`, `armv6` or `armv7`
ARCH=amd64
PLATFORM=$(uname -s)_$ARCH
curl -sLO "https://github.com/eksctl-io/eksctl/releases/latest/download/eksctl_$PLATFORM.tar.gz"
# (Optional) Verify checksum
curl -sL "https://github.com/eksctl-io/eksctl/releases/latest/download/eksctl_checksums.txt" | grep $PLATFORM | sha256sum --check
tar -xzf eksctl_$PLATFORM.tar.gz -C /tmp && rm eksctl_$PLATFORM.tar.gz
sudo mv /tmp/eksctl /usr/local/bin

From ExampleConfigs select simple cluster

https://github.com/eksctl-io/eksctl/blob/main/examples/01-simple-cluster.yaml

eks.yaml in 16-Docker -- To create cluster

eksctl create cluster --config-file=eks.yaml
eksctl delete cluster --config-file=eks.yaml

aws configure

AWS cloudformation -- Just like terraform infra as code - AWS native service - will create resouces for cluster

kubectl get nodes -- to get the no of nodes in the cluster

namespace 
---------- 
isolated project space similar to VPC where you can control resources to your project

default namespace is created along with cluster creation

kubectl get namespace -- to get the namespaces

Kind -- kind of resource
apiVersion  -- kubernetes version
metadata 
  name -- resource name
  
spec used for other resouces 

kubectl create -f 01-namespace.yaml -- will throw error if the resource alrady exists
kubectl apply -f 01-namespace.yaml  -- will throw warning not error if the resource alrady exists
kubectl delete -f 01-namespace.yaml -- delete the resource


pod
====
docker --> image --> container
k8s    --> image --> pod

pod vs container
----------------
pod is the smallest deployable unit in k8s .pod can have multiple containers
all containers in pod share the same ip and storage
multiple containers are useful in few applications like shipping the logs through sidecars

kubectl apply -f 02-pod.yaml
kubectl get pods -- to get the list of pods
kubectl get pods -n <namespace> -- to get the list of pods in namespace

kubectl exec -it <pod-name> -- bash
kubectl exec -it nginx -- bash  # To connect to pod

To connect pod in expense namespace
kubectl exec -it nginx -n expense -- bash

kubectl apply -f 03-multicontainer.yaml
kubectl get pods
CrashLoopBackOff -- error when failed to create container

kubectl pod describe <pod-name>  -- to get the details of pod like which container is failing  in a pod

# If one container failed we need to delete the pod and create it again
kubectl delete -f 03-multicontainer.yaml

kubectl exec -it <pod-name> -- bash

kubectl exec -it multi-containers -- bash

curl  localhost

By default it will connect to first container
To connect to second contianer

kubectl exec -it <pod-name> -c <container-name> -- bash

kubectl exec -it multi-containers -c almalinux -- bash

curl localhost

curl output will be same because "all conatiners in pod share the same ip and storage"

pod or container is ephemeral

when pod is deleted application logs created by first container will also get deleted 
so we will create second container(sidecar container) to push the logs to ELK to reduce the load on first container

labels
-------
labels are used to provide metadata and can be used to attach other resources

kubectl apply -f 04-labels.yaml

annotations
------------
annotations are similar to labels 
labels can be used to select internal resources 
annotations can be used to select external resources
also in annotations we can give special characters and used in ingress controller
special characters cannot be used in labels

kubectl apply -f 05-annotations.yaml

--------------------------------------------------------------------------------------------------------
env
To set environment variables
kubectl apply -f 06-env.yaml
kubectl exec -it env -- bash
# env

resources
 requests
 limits
sets the min and max RAM and CPU for container        
kubectl apply -f 07-resources.yaml
kubectl top pod  --- to check the resources consumed by pod

ConfigMap
  data
To provide configurations as env variables

kubectl apply -f 08-config-map.yaml
kubectl get configmap
kubectl describle configmap myconfig

Referring ConfigMap to set as env variables

envFrom
 configMapRef

 kubectl apply -f 09-pod-config.yaml
 kubectl exec -it pod-config -- bash  
 env
 
 Update config map data and restart pod
kubectl apply -f 08-config-map.yaml

 kubectl delete -f 09-pod-config.yaml
 kubectl apply -f 09-pod-config.yaml
 kubectl exec -it pod-config -- bash  
 env

secrets
 data
secret types
  opaque
  
$  echo -n "testsecret" | base64
dGVzdHNlY3JldA==

$ echo "dGVzdHNlY3JldA==" | base64 --decode
testsecret
kubectl apply -f 10-secret.yaml
kubectl get secret
kubectl describe secret dotfile-secret

Referring secret to set as env variables

envFrom
 secretRef

 kubectl apply -f 11-pod-secret.yaml
 kubectl exec -it pod-secret -- bash  
 env 
 
Service
=========
service is used for 
1. load balancing
2. pod to pod communication
3. as DNS between pods

Ip address of pod will changes after deletion and creation of pod
Instead of IP we will create service to access the pod or pod to pod communication with service name

service will be cretad with clusterip
kubectl delete pods --all --all-namespaces   -- to delete all pods

kubectl apply -f 12-service.yaml

kubectl get svc --- to get service info -- gives cluster IP and also node port

kubectl get pod -o wide -- to get pod ip and also the node where pod is running

start other container to check service access from other container

kubectl apply -f 03-multicontainer.yaml

kubectl exec -it multi-containers -- bash

then curl <servicename>

curl nginx

apt update
apt install dnsutils -y

nslookup nginx

multi-container --> curl nginx --> 
3 types of services
1. cluster IP --> default, only works internally i.e., pod to pod
2. NodePort --> external requests
3. LoadBalancer --> only works with cloud providers. here service open classic LB. 

clusterip will not work in internet, works only in kubernetes i.e., only works internally i.e., pod to pod

Node port
---------
Node port works from internet
Node port automatically creates cluster IP and creates new node port

kubectl delete -f 12-service.yaml
kubectl apply -f 13-node-port.yaml

kubectl get svc --- to get service info -- gives cluster IP and also node port

kubectl get pod -o wide -- to get pod ip and also the node where pod is running

check the private ip address of node from aws ui
copy  the node public ip address and access with node port from browser(open port in security group)

If we acess the node port with any node ip it will work because kubernetes will send the request to the correct pod

In NodePort type
when user send request with public ip(any instance/node public IP) ip:nodeport
then kubernetes will forward the request to cluster ip service
then cluster ip service will forward the request to the pod
When we open port in security group Kubernetes will open node port on all instances(nodes) so we the url will work with any instance ip and node port

# test with url
# http:<AnyInstancePublicIP>:<NodePort>

kubectl delete -f 13-node-port.yaml

kubectl apply -f 14-load-balancer.yaml

In Load Balancer type
request will come from user to Load balancer listening on port 80 
then LB will forward to node port to any one of the instances(nodes) in the cluster
then from any one of the instances(node) request goes to cluster ip
then finally request will be sent from cluster ip to the pod

# test with url
# http:<LB_DNS_Name>:<NodePort>

# create Route53 record for LB DNS name with domain name to access the url with domain name











